---
title: "Zero tolerance ecology and the mapping of pathogens."
author: "Andrew J. Tyre, Jonathan Rhodes, Tara Martin and Elizabeth VanWormer"
site: bookdown::bookdown_site
documentclass: article
bibliography: vet-obserror.bib
biblio-style: "apalike"
link-citations: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(huxtable)
```


# Abstract

A fundamental question in ecology broadly has to do with how species are distributed in space, and which biotic and abiotic characteristics of the environment explain that distribution. Veterinary epidemiology could use the same tools to understand environmental drivers of pathogens. Unfortunately, the ecological and epidemiological data used to build species distribution models suffers from imperfect detection, creating both false presences and false absences. The ecological community developed a wide range of two-stage models to compensate for these errors. Here we explore how those tools could be used by veterinary epidemiologists to map the prevalence of pathogens.

Errors arise from a variety of mechanisms in the data generating process. The sources of errors also vary by the scale of inference. We review the recent ecological and epidemiological literature on error processes. Then we examine common types of epidemiological data through this lens to identify errors of the same type as ecology, as well as errors unique to epidemiological studies. For example, pooled samples used to detect pathogens in vector species generate a particular kind of prevalence data with a unique error structure. 

We review the tools developed by ecologists to mitigate the effects of errors, and consider the applicability of these approaches to epidemiological data. For epidemiologists to apply these tools requires changes in study design to generate the data necessary to support two stage models. We finish by describing the opportunities for future work created by the intersection of species distribution modelling and pathogen mapping. 

# Introduction

Observations of reality are imprecise and fraught with error from many sources. Arguably, the science of statistics was invented to deal with this fact. In many disciplines, the error in observations can be well described by a Gaussian, or normal, distribution. Statistics is well equipped to deal with those cases! In a few disciplines, errors take on different structures that are not normal (pun intended). Sometimes simply changing the distribution we assume the observations are following is sufficient to regain a powerful suite of tools to draw conclusions. But in a few cases, even that is not sufficient. 

Imagine trying to determine the prevalence of a pathogen in a population out in nature. The most basic observation, is this individual infected (or has been infected in the past), is a simple binomial variable. Even that observation has errors -- there are few (maybe no?) methods for detecting pathogen in a tissue sample of an individual that have no false positive or negatives. But even if our method is perfect, going from a infected proportion of a sample of individuals back to the prevalence in the population is fraught with difficulty. We must assume that the individuals captured are a random sample of the population; that is, infected and uninfected individuals are both randomly distributed and equally likely to be captured. If we are taking samples from across a series of habitat patches in a fragmented landscape, we may also find that no individuals were captured at a particular patch at all. Does that mean the species is absent, and if not, what is the prevalence in that patch? The answers to that final question depend a great deal on the methods of sampling and how sampling effort is distributed in space.

A fundamental question in ecology broadly has to do with how species are distributed in space, and which biotic and abiotic characteristics of the environment explain that distribution. The sub-discipline of "species distribution modelling" is the art of answering this question. Historically, the details of how an observation of a species at a particular point in time and space arose were largely ignored (cite some early paper here). Species distribution models were built assuming that the presence and absence of a species at some series of points was known with certainty (or cite some examples here). Although this assumption was widely known to be false, there did not seem to be any methods both testing this assumption and mitigating its effects. 

The primary issue arising from assuming observations are accurate when they are not is bias [@tyre2003improving]. If a species is sometimes missed when present, a false negative, estimates of the effects of covariates on the probability of presence are biased towards zero. **is there a paper looking at effects of false positives in a similar broad way? Yes, follow up on blog post from Jonathan.**

Understanding the distribution of pathogens is complicated by the fact that the habitat of the pathogen, the host population, is even more fragmented than the habitat of the host species. 

A wildlife pathogen example of habitat mapping is Chronic Wasting Disease in deer [@evans2015_habitat_cwd]. These approaches are being used to prioritize areas for management (citations therein). Other examples of risk mapping from Liz.

We must make predictions [@houlahan2017priority] to demonstrate understanding of these systems. Quantitative predictions are risky, and to make them we need statistical and mathematical models.

Another example is the distribution of different strains of *Toxoplasmosis gondii* across the land-sea interface [@vanwormer2014toxolandsea]. 

# Sources of extra zeros

Summarize @martin2005zero, and update with more recent thinking. Provide some veterinary examples?

We expect to measure zeros in ecology. Whether that zero is in the context of a presence/absence measurement, or a count distribution, zeros are a natural and expected part of ecology. However, zeros sometimes form the majority of the observations, and we start to encounter problems building predictive models on that basis. Zeros arise from a number of mechanisms that vary according the scale (extent and resolution) of a study. So called 'zero-inflated' data can arise from the true process being studied. But it can also arise from the process used to collect the data, the observation process. 

Martin et al [-@martin2005zero] categorized excess zeros into four sources, depending on whether they are true zeros (part of the biological process), or false zeros (arising from the observation process). 

```{r source-of-zeros-table, echo=FALSE}
source_of_zeros <- tribble(
  ~source, ~definition,
  "Type of Zero",     "Definition",
    "True Zero",       "Species does not occur at a site because of the ecological process, or effect, under study.",
  "",                "Species does not saturate it's entire suitable habitat, by chance.",
  "False Zero",      "Species occurs at a site, but is not present during the study period.",
  "",                "Species occurs at a site and is present, but is cryptic and difficult to detect."
)
ht <- huxtable(source_of_zeros)
caption(ht) <- "Types of zeros arising in ecological data when a site or patch of habitat is the focus of prediction."
theme_article(ht)
```

True zeros [Table 1] arise when the species is absent from the unit of observation for ecological or epidemiological reasons. When sampling a patch of habitat containing a population of hosts, a true zero means the prevalence is zero. This could arise because the habitat patch is empty of potential hosts, or the hosts present are unsuitable, or the parasite may not have dispersed to the patch yet. 

False zeros arise from characteristics of the observation process. At ecological scales, one type of zero arises when the unit of observation is smaller than the home range of the species in question. The site or patch is used by the species, but at the particular time of the study individuals of that species are in a different part of their home range, and impossible to detect. This type of false zero is not an issue for parasites, but it is a possible problem when studying hosts. A second problem arises when the species is present during the study, but goes undetected. For epidemiological studys this arises if the method used to detect the parasite (or past infection of the parasite), has a non-zero probability of detecting the parasite in a particular sample. A method with low sensitivity has a high probability of a false negative. In some cases we have an estimate of the sensitivity of a method, but this is (to my knowledge) rarely used directly in species distribution modelling.  

What are the questions and what kind of data are collected?
Pooled sampling of mosquitoes - minimum prevalence
What drives detectability in epidemiological samples and are they different 

## Scale of questions

There are two important spatial scales to consider. First, what is the resolution of the ecological / epidemiological process? Is the ecology about a population within a discrete patch of habitat, or about the larger meta-population operating across many patches of habitat. 

infographic / toy examples

# Tools for mitigating extra zeros

The primary tool for reducing the bias associated with false negatives is to shift the design of a study so that sample points are studyed more than once. Even without more complex statistics, this approach reduces bias by providing more opportunities to detect the species at a given sample point. This does induce a severe trade-off: visiting the same points more than once reduces the number of points that can be sampled if the amount of effort is held constant. It is possible to identify an optimal level for this trade off that depends on the goals of the study [@field2005optimizing, @mackenzie2005designing]. 

In the context of mapping a , if the sample point is represented by a population of hosts, then sampling > 1 host per point has the same effect as repeat visits. The same trade off also exists -- the more individuals sampled at one site the fewer different sites can be sampled with a fixed amount of effort. This is especially true if analyzing a sample for the presence of a pathogen is expensive. In herd and vector surveillance samples are often pooled across individuals to reduce costs, but this comes at the expense of some information.

how to estimate false negatives? repeat observations?

Dynamic detection error models -- cross-sectional vs. longitudinal studies

Joint occurrence / co-occurrence SDM

# Future directions

Designs accommodating false positive/negative rates at the pointy end

# References {-}


